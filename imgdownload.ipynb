{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from io import BytesIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url, timeout=10)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "def extract_text_from_image(image):\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def process_image_row(row):\n",
    "    index, image_url = row\n",
    "    try:\n",
    "        # Download the image\n",
    "        image = download_image(image_url)\n",
    "\n",
    "        # Extract text from the image\n",
    "        text = extract_text_from_image(image).lower()\n",
    "        return index, text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_url}: {str(e)}\")\n",
    "        return index, ''\n",
    "\n",
    "def process_csv(csv_file):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Ensure there's a column named 'image_link'\n",
    "    if 'image_link' not in df.columns:\n",
    "        raise ValueError(\"CSV file must have a column named 'image_link'\")\n",
    "\n",
    "    # Create a new column for extracted text\n",
    "    df['extracted_text'] = ''\n",
    "\n",
    "    # Use ThreadPoolExecutor to parallelize the process\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        # Create tasks for each row in the DataFrame\n",
    "        futures = {executor.submit(process_image_row, (index, row['image_link'])): index for index, row in df.iterrows()}\n",
    "\n",
    "        # Process results as they complete\n",
    "        for future in as_completed(futures):\n",
    "            index, text = future.result()\n",
    "            df.at[index, 'extracted_text'] = text\n",
    "            print(f\"Processed image {index + 1}/{len(df)}\")\n",
    "\n",
    "    # Remove the 'image_link' column\n",
    "    df = df.drop('image_link', axis=1)\n",
    "\n",
    "    # Save results to a new CSV file\n",
    "    output_file = 'ocr_results.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_csv(\"train_1000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ocr_results_preprocessed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 170\u001b[0m\n\u001b[0;32m    168\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocr_results_preprocessed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    169\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_preprocessed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 170\u001b[0m \u001b[43mprocess_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 128\u001b[0m, in \u001b[0;36mprocess_csv\u001b[1;34m(input_file, output_file)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_csv\u001b[39m(input_file, output_file):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;66;03m# Read the input CSV file\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# Ensure required columns exist\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ocr_results_preprocessed.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to string if the input is not already a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    # Remove any non-ASCII characters and normalize spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    \n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "def extract_measurement(text, patterns):\n",
    "    text = clean_text(text)\n",
    "    all_matches = []\n",
    "    for pattern, unit_map in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            value, unit = match\n",
    "            unit = unit.lower()\n",
    "            if unit in unit_map:\n",
    "                unit = unit_map[unit]\n",
    "            all_matches.append(f\"{value} {unit.lower()}\")\n",
    "    return ', '.join(all_matches) if all_matches else 'N/A'\n",
    "\n",
    "def convert_to_grams(value, unit):\n",
    "    \"\"\"Convert various units to grams.\"\"\"\n",
    "    conversion_factors = {\n",
    "        'g': 1,\n",
    "        'kg': 1000,\n",
    "        'lb': 453.592,\n",
    "        'oz': 28.3495,\n",
    "        't': 1000000\n",
    "    }\n",
    "    return value * conversion_factors.get(unit, 1)\n",
    "\n",
    "def extract_weight(text):\n",
    "    patterns = [\n",
    "        (r'\\b(\\d{1,3}(?:[.,]\\s*\\d{1,3})?)\\s*(g|gram|grams|gm|kg|kilogram|kilograms|lb|lbs|pound|pounds|oz|ounce|ounces|t|ton|tons)\\b'\n",
    ",\n",
    "         {'gram': 'g', 'grams': 'g', 'kilogram': 'kg', 'kilograms': 'kg', 'pound': 'lb', 'pounds': 'lb', 'ounce': 'oz', 'ounces': 'oz', 'ton': 't', 'tons': 't'})\n",
    "    ]\n",
    "    return extract_measurement(text, patterns)\n",
    "\n",
    "def extract_max_weight(text):\n",
    "    patterns = [\n",
    "        (r'\\b(\\d{1,3}(?:[.,]\\s*\\d{1,3})?)\\s*(g|gram|grams|gm|kg|kilogram|kilograms|lb|lbs|pound|pounds|oz|ounce|ounces|t|ton|tons)\\b',\n",
    "         {'gram': 'g', 'grams': 'g', 'kilogram': 'kg', 'kilograms': 'kg', 'pound': 'lb', 'pounds': 'lb', 'ounce': 'oz', 'ounces': 'oz', 'ton': 't', 'tons': 't'})\n",
    "    ]\n",
    "    \n",
    "    # Extract all measurements\n",
    "    measurements = extract_measurement(text, patterns)\n",
    "    \n",
    "    if not measurements:\n",
    "        return ''  # No weights found\n",
    "    \n",
    "    # Initialize lists to hold weight values and units\n",
    "    weight_data = []\n",
    "\n",
    "    # Split the measurements and convert to grams\n",
    "    for measurement in measurements.split(', '):\n",
    "        parts = measurement.split(' ')\n",
    "        if len(parts) == 2:\n",
    "            value, unit = parts\n",
    "            try:\n",
    "                weight_data.append((float(value), unit))\n",
    "            except ValueError:\n",
    "                continue  # Skip if the value conversion fails\n",
    "\n",
    "    if not weight_data:\n",
    "        return ''  # No valid weights found\n",
    "\n",
    "    # Convert all weights to grams\n",
    "    weight_in_grams = [(convert_to_grams(value, unit), unit) for value, unit in weight_data]\n",
    "    \n",
    "    # Find the maximum weight in grams\n",
    "    max_weight_grams, max_unit = max(weight_in_grams, key=lambda x: x[0])\n",
    "    \n",
    "    # Convert the maximum weight back to the appropriate unit\n",
    "    conversion_factors = {'g': 1, 'kg': 1000, 'lb': 453.592, 'oz': 28.3495, 't': 1000000}\n",
    "    for unit, factor in sorted(conversion_factors.items(), key=lambda x: x[1], reverse=True):\n",
    "        if max_weight_grams >= factor:\n",
    "            max_weight = max_weight_grams / factor\n",
    "            return f\"{max_weight:.2f} {unit.lower()}\"\n",
    "    \n",
    "    return f\"{max_weight_grams:.2f} g\"\n",
    "\n",
    "\n",
    "def extract_dimension(text):\n",
    "    patterns = [\n",
    "        (r'\\b(\\d{1,3}(?:[.,]\\s*\\d{1,3})?)\\s*(m|meter|meters|CM|C.M.|cm|centimeter|centimeters|MM|mm|millimeter|millimeters|ft|foot|feet|in|inch|inches)\\b',\n",
    "         {'meter': 'm', 'meters': 'm', 'centimeter': 'cm', 'centimeters': 'cm', 'millimeter': 'mm', 'millimeters': 'mm', 'foot': 'ft', 'feet': 'ft', 'inch': 'in', 'inches': 'in'})\n",
    "    ]\n",
    "    return extract_measurement(text, patterns)\n",
    "\n",
    "def extract_voltage(text):\n",
    "    patterns = [\n",
    "        (r'\\b(\\d{1,3}(?:[.,]\\s*\\d{1,3})?)\\s*(V|volt|volts|kV|kilovolt|kilovolts|mV|millivolt|millivolts)\\b',\n",
    "         {'volt': 'V', 'volts': 'V', 'kilovolt': 'kV', 'kilovolts': 'kV', 'millivolt': 'mV', 'millivolts': 'mV'})\n",
    "    ]\n",
    "    return extract_measurement(text, patterns)\n",
    "\n",
    "def extract_wattage(text):\n",
    "    patterns = [\n",
    "        (r'\\b(\\d{1,3}(?:[.,]\\s*\\d{1,3})?)\\s*(W|watt|watts|kW|kilowatt|kilowatts|mW|milliwatt|milliwatts)\\b',\n",
    "         {'watt': 'W', 'watts': 'W', 'kilowatt': 'kW', 'kilowatts': 'kW', 'milliwatt': 'mW', 'milliwatts': 'mW'})\n",
    "    ]\n",
    "    return extract_measurement(text, patterns)\n",
    "\n",
    "def extract_volume(text):\n",
    "    patterns = [\n",
    "        (r'\\b(\\d{1,3}(?:[.,]\\s*\\d{1,3})?)\\s*(l|liter|liters|ml|milliliter|milliliters|gal|gallon|gallons|fl\\s*oz|fluid\\s*ounce|fluid\\s*ounces)\\b',\n",
    "         {'liter': 'l', 'liters': 'l', 'milliliter': 'ml', 'milliliters': 'ml', 'gallon': 'gal', 'gallons': 'gal', 'fluid ounce': 'fl oz', 'fluid ounces': 'fl oz'}),\n",
    "        (r'\\b(\\d{1,3}(?:[.,]\\s*\\d{1,3})?)\\s*(cu\\s*in|cubic\\s*inch|cubic\\s*inches|cu\\s*ft|cubic\\s*foot|cubic\\s*feet|cu\\s*m|cubic\\s*meter|cubic\\s*meters|cu\\s*cm|cubic\\s*centimeter|cubic\\s*centimeters)\\b',\n",
    "         {'cubic inch': 'cu in', 'cubic inches': 'cu in', 'cubic foot': 'cu ft', 'cubic feet': 'cu ft', 'cubic meter': 'cu m', 'cubic meters': 'cu m', 'cubic centimeter': 'cu cm', 'cubic centimeters': 'cu cm'})\n",
    "    ]\n",
    "    return extract_measurement(text, patterns)\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def process_csv(input_file, output_file):\n",
    "    # Read the input CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['extracted_text'] = df['extracted_text'].fillna('')\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_columns = ['extracted_text', 'entity_name',\"entity_value\"]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"CSV file must have columns: {', '.join(required_columns)}\")\n",
    "    \n",
    "    # Create a dictionary mapping entity names to their respective extraction functions\n",
    "    extraction_functions = {\n",
    "        'item_weight': extract_weight,\n",
    "        'width': extract_dimension,\n",
    "        'height': extract_dimension,\n",
    "        'depth': extract_dimension,\n",
    "        'maximum_weight_recommendation': extract_max_weight,\n",
    "        'voltage': extract_voltage,\n",
    "        'wattage': extract_wattage,\n",
    "        'item_volume': extract_volume\n",
    "    }\n",
    "    \n",
    "    # Process each row\n",
    "    df['prediction'] = df.apply(lambda row: \n",
    "        extraction_functions.get(row['entity_name'].lower(), lambda x: 'N/A')(row['extracted_text']),\n",
    "        axis=1)\n",
    "    \n",
    "    # Replace 'N/A' with empty string and ensure all values are strings\n",
    "    df['prediction'] = df['prediction'].replace('N/A', '').astype(str)\n",
    "    \n",
    "    # Create a new DataFrame with index and prediction\n",
    "    result_df = df[['prediction']].copy()\n",
    "    \n",
    "    # Reset index to ensure the index column starts from 0\n",
    "    result_df.reset_index(inplace=True)\n",
    "    result_df.rename(columns={'index': 'index'}, inplace=True)\n",
    "    \n",
    "    # Save the result to a new CSV file, including the index\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = 'ocr_results.csv'\n",
    "output_file = 'output.csv'\n",
    "process_csv(input_file, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to final_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Dictionary mapping of entity to their allowed units\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Dictionary mapping short forms to long forms of units\n",
    "unit_conversions = {\n",
    "    'cm': 'centimetre',\n",
    "    'ft': 'foot',\n",
    "    'in': 'inch',\n",
    "    'm': 'metre',\n",
    "    'mm': 'millimetre',\n",
    "    'yd': 'yard',\n",
    "    'g': 'gram',\n",
    "    'kg': 'kilogram',\n",
    "    'mcg': 'microgram',\n",
    "    'mg': 'milligram',\n",
    "    'oz': 'ounce',\n",
    "    'lb': 'pound',\n",
    "    'lbs': 'pound',\n",
    "    't': 'ton',\n",
    "    'kv': 'kilovolt',\n",
    "    'mv': 'millivolt',\n",
    "    'v': 'volt',\n",
    "    'kw': 'kilowatt',\n",
    "    'w': 'watt',\n",
    "    'cl': 'centilitre',\n",
    "    'cu ft': 'cubic foot',\n",
    "    'cu in': 'cubic inch',\n",
    "    'dl': 'decilitre',\n",
    "    'fl oz': 'fluid ounce',\n",
    "    'gal': 'gallon',\n",
    "    'imp gal': 'imperial gallon',\n",
    "    'L': 'litre',\n",
    "    'ÂµL': 'microlitre',\n",
    "    'ml': 'millilitre',\n",
    "    'pt': 'pint',\n",
    "    'qt': 'quart'\n",
    "}\n",
    "\n",
    "# Function to convert units\n",
    "def convert_units(text):\n",
    "    # This regex captures numbers with units directly attached (e.g., '10cm') or separated by space (e.g., '10 cm')\n",
    "    pattern = r'(\\d+(?:\\.\\d+)?)\\s*([a-zA-Z]+)'\n",
    "    \n",
    "    # Function to replace short form with long form using the conversion dictionary\n",
    "    def replace_unit(match):\n",
    "        number, unit = match.groups()\n",
    "        unit = unit.lower()  # Convert unit to lowercase\n",
    "        if unit in unit_conversions:  # Check if the unit is in the conversion dictionary\n",
    "            return f\"{number} {unit_conversions[unit]}\"  # Replace with long form\n",
    "        return match.group(0)  # If not found, return the original match\n",
    "\n",
    "    # Apply the regex substitution to the text\n",
    "    converted_text = re.sub(pattern, replace_unit, text)\n",
    "    return converted_text\n",
    "\n",
    "# Function to process the CSV file\n",
    "def process_csv(input_file, output_file):\n",
    "    # Read the input CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Handle null values in the 'prediction' column\n",
    "    df['prediction'] = df['prediction'].fillna('')  # Replace NaN with an empty string or any other placeholder\n",
    "    \n",
    "    # Convert units in the 'prediction' column\n",
    "    df['prediction'] = df['prediction'].apply(convert_units)\n",
    "    \n",
    "    # Save the result to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = 'output_preprocessed.csv'\n",
    "output_file = 'final_preprocessed.csv'\n",
    "process_csv(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('final_preprocessed.csv')\n",
    "\n",
    "# Update the 'prediction' column to only keep the first value before the ', ' (comma and space)\n",
    "# Handle null cells by checking if the value is a string before splitting\n",
    "df['prediction'] = df['prediction'].apply(lambda x: x.split(', ')[0] if isinstance(x, str) else x)\n",
    "df['prediction'] = df['prediction'].replace(',', '.', regex=True)\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "\n",
    "df.to_csv('final_preprocessed.csv', index=False)\n",
    "\n",
    "print(\"CSV file updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"final_preprocessed.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to calculate Precision, Recall, and F1 Score\n",
    "def calculate_f1_score(df):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "\n",
    "    # Loop over each row to classify each prediction as TP, FP, FN, or TN\n",
    "    for index, row in df.iterrows():\n",
    "        gt = row['entity_value']\n",
    "        out = row['prediction']\n",
    "        \n",
    "        if out != \"\" and gt != \"\" and out == gt:\n",
    "            true_positives += 1\n",
    "        elif out != \"\" and gt != \"\" and out != gt:\n",
    "            false_positives += 1\n",
    "        elif out == \"\" and gt != \"\":\n",
    "            false_negatives += 1\n",
    "        elif out == \"\" and gt == \"\":\n",
    "            true_negatives += 1\n",
    "\n",
    "    # Calculate Precision, Recall, and F1 Score\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "calculate_f1_score(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
